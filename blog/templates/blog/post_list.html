<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IA Blog</title>
</head>
<body>
    <div>
        <h1>Enfoque en Hardware y Límites Físicos</h1>
        <h2>El Muro de la Energía: ¿Por qué la Ley de Moore ya no es suficiente para la IA?</h2>
        <p>Mientras los modelos de IA crecen exponencialmente, duplicando su tamaño cada pocos meses, hay una ley que no
            pueden
            violar: las leyes de la física. Nos obsesionamos con los parámetros de los LLMs, pero rara vez miramos el coste
            real detrás de cada respuesta de ChatGPT: la energía. Estamos chocando contra un muro, y no es solo de código, es un
            muro de energía.
            <br>
            <strong>(La Crisis del Crecimiento Exponencial)</strong>
            El entrenamiento de GPT-3 se estima que consumió alrededor de 1,300 MWh de electricidad. Esto es equivalente al
            consumo anual de más de 100 hogares estadounidenses. Y eso es solo el entrenamiento. La inferencia—ejecutar el
            modelo para responder a cada una de las millones de peticiones de usuarios—es donde el coste energético se
            multiplica y se vuelve insostenible con los modelos actuales.
        </p>
    </div>
        </body>
</html>